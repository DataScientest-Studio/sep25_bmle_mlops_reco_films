from __future__ import annotations
import os
from pathlib import Path
import time
import requests
import pandas as pd
import streamlit as st

try:
    ROOT = Path(__file__).resolve().parents[2]
except IndexError:
    ROOT = Path(__file__).resolve().parent

MOVIELENS_IMG = ROOT / "src" / "streamlit" / "movielens.png"
DATA_IMG = ROOT / "src" / "streamlit" / "pipeline_data_IMG.png"
viz1_IMG = ROOT / "Reports" / "figures" / "visualize_Figure_1.png"
viz2_IMG = ROOT / "Reports" / "figures" / "visualize_Figure_2.png"
SQL1_IMG = ROOT / "Reports" / "figures" / "SQL1.png"
archi_IMG = ROOT / "Reports" / "figures" / "architecture.png"

DEFAULT_FIG_DIRS = [
    ROOT / "Reports" / "figures",
    ROOT / "reports" / "figures",
    ROOT / "assets",
    ROOT / "Assets",
]

st.set_page_config(
    page_title="SystÃ¨me de recommandation de films (Soutenance)",
    page_icon="ğŸ¬",
    layout="wide",
)

APP_TITLE = "ğŸ¬ CrÃ©ation d'un systÃ¨me de recommandation de films"

API_URL = os.getenv("API_URL", "http://127.0.0.1:8000")

MLFLOW_INTERNAL_URL = os.getenv("MLFLOW_TRACKING_URI", "http://127.0.0.1:5000")

MLFLOW_EXTERNAL_URL = "http://127.0.0.1:5000" 

def slide_header(title: str, subtitle: str | None = None) -> None:
    st.markdown(f"## {title}")
    if subtitle:
        st.caption(subtitle)
    st.markdown("---")

def key_takeaways(title, items: list[str]) -> None:
    st.markdown(f"### âœ… {title}")
    for it in items:
        st.markdown(f"- **{it}**")

def find_first_existing(paths: list[Path]) -> Path | None:
    for p in paths:
        if p.exists():
            return p
    return None

def list_pngs_in_known_dirs() -> dict[str, Path]:
    found: dict[str, Path] = {}
    for d in DEFAULT_FIG_DIRS:
        if d.exists() and d.is_dir():
            for p in d.glob("*.png"):
                found[p.name] = p
    return found

def show_png_if_exists(filename_contains: str, png_map: dict[str, Path], caption: str | None = None) -> bool:
    needle = filename_contains.lower()
    for name, path in png_map.items():
        if needle in name.lower():
            st.image(str(path), caption=caption, use_container_width=True)
            return True
    return False

def check_api_health():
    """VÃ©rifie si l'API est en ligne"""
    try:
        response = requests.get(f"{API_URL}/health", timeout=1)
        if response.status_code == 200:
            return True
    except:
        return False
    return False

def show_presentation_mode():
    
    png_map = list_pngs_in_known_dirs()

    st.sidebar.markdown("---")
    st.sidebar.header("ğŸ§­ Navigation Slides") 
    SECTIONS = [
        "Contexte & objectifs",
        "Architecture gÃ©nÃ©rale",
        "ModÃ¨le & mÃ©triques dâ€™Ã©valuation",
        "Suivi des ExpÃ©riences via MLflow",    
        "Monitoring & maintenance",
        "Conclusion & perspectives",
    ]
    section = st.sidebar.radio("Aller Ã  :", SECTIONS, index=0)

    st.sidebar.markdown("---")
    st.sidebar.caption("""
                    Pierre Barbetti       
                    RaphaÃ«l Da Silva       
                    Martine Mateus       
                    Laurent Piacentile
                    """)

    if section == "Contexte & objectifs": 
        slide_header("Contexte & objectifs")
        
        st.markdown("## ğŸ§ª **Cadre du projet**")
        
        st.markdown("""
        ### ğŸ¯ Objectif : DÃ©ployer un systÃ¨me de recommandation de films 
        
        ### Cadre technique :
        - MLOps : Automatiser et monitorer le cycle de vie d'un projet ML
        - Disposer d'une application de recommandation de films en production
        
        ### Choix de conception :
        - Item-Based Collaborative Filtering : similaritÃ© entre films en fonction des comportements utilisateurs
        - Tables de recommandations gÃ©nÃ©rÃ©es offline, pas d'infÃ©rence en direct
        """)
            
        st.markdown("""
        ## ğŸ¯ Focus sur les pratiques MLOps / performances de l'architecture
        
        - Architecture robuste de type microservices
        - Versioning des donnÃ©es et des modÃ¨les
        - ReproductibilitÃ© et traÃ§abilitÃ©
        - Monitoring des mÃ©triques en production
        - Documentation claire
                    
        Aspects spÃ©cifiques du projet :  
        - rÃ©soudre la problÃ©matique de cold-start.
        """)

    elif section == "Architecture gÃ©nÃ©rale":
        slide_header("ğŸ§· Architecture gÃ©nÃ©rale")
        st.subheader("SchÃ©ma de l'architecture MLOps conteneurisÃ©e")
        
        if archi_IMG.exists():
            st.image(str(archi_IMG), caption="SchÃ©ma MLOps", use_container_width=True)
        else:
            st.warning("Image introuvable: architecture.png")

    elif section == "Bases de donnÃ©es PostgreSQL":
        slide_header("Bases de donnÃ©es")    
        st.subheader("Architecture de la base de donnÃ©es PostgreSQL")
        
        col1, col2 = st.columns(2)
        with col1:
            if SQL1_IMG.exists():
                st.image(str(SQL1_IMG), caption="SchÃ©ma DB", use_container_width=True)
            else:
                st.warning("Image introuvable: SQL1.png")
        with col2:
            st.success("**Versioning des donnÃ©es**")

        st.write("---")
        st.subheader("ğŸ“Š Exploration des donnÃ©es MovieLens")
        st.markdown("*https://grouplens.org/datasets/movielens/20m/*")
        
        col1, col2 = st.columns(2)
        with col1:
            if viz1_IMG.exists():
                st.image(str(viz1_IMG), caption="MovieLens â€” En chiffres", use_container_width=True)
        with col2:
            if viz2_IMG.exists():
                st.image(str(viz2_IMG), caption="MovieLens â€” En graphiques", use_container_width=True)

    elif section == "ModÃ¨le & mÃ©triques dâ€™Ã©valuation":
        slide_header(
            "ğŸ” ModÃ¨le & mÃ©triques dâ€™Ã©valuation",
            "Item-based CF + Ã©valuation orientÃ©e ranking (Top-10)"
        )

        st.subheader("ğŸ¯ ModÃ¨le : Item-Based Collaborative Filtering (ItemCF)")

        col1, col2 = st.columns(2)

        with col1:
            st.info("""
            ### ğŸ”¹ Principe
            - Chaque film est reprÃ©sentÃ© par un **vecteur de notes utilisateurs** (user-item matrix).
            - On calcule la similaritÃ© **cosine** entre les films.
            - On conserve les **K voisins** les plus similaires par film (**offline**).
            - En recommandation (online), on agrÃ¨ge les voisins des films vus et on **rank** les candidats.

            ğŸ‘‰ ModÃ¨le explicable, rapide en infÃ©rence, adaptÃ© aux systÃ¨mes Top-N.
            """)

        with col2:
            st.info("""
            ### ğŸ”¹ Scoring (ranking)
            - On part de lâ€™historique utilisateur (films dÃ©jÃ  vus).
            - On rÃ©cupÃ¨re les voisins item-item et on agrÃ¨ge un score.
            - On exclut les films dÃ©jÃ  vus.
            - On retourne le **Top-10**.

            âœ”ï¸ Offline: calcul voisinage / index  
            âœ”ï¸ Online: scoring lÃ©ger + tri  
            âœ”ï¸ Usage production : faible latence  
            """)

        st.markdown("---")

        st.subheader("ğŸ§Š Gestion du Cold-Start")

        col1, col2 = st.columns(2)

        with col1:
            st.success("""
            ### ğŸ”¹ Nouveaux utilisateurs
            Fallback vers une recommandation **popularitÃ© bayÃ©sienne** :
            - robuste aux faibles volumes de notes
            - Ã©vite de survaloriser des films avec peu de ratings
            - garantit une recommandation mÃªme sans historique
            """)

        with col2:
            st.success("""
            ### ğŸ”¹ Robustesse produit
            - Le pipeline garantit toujours un Top-N
            - Le systÃ¨me gÃ¨re explicitement les cas sans historique utilisateur
            - Le fallback vers la popularitÃ© assure une continuitÃ© de service
            """)

        st.markdown("---")

        st.subheader("ğŸ“Š MÃ©triques dâ€™Ã©valuation (Top-10 Ranking Metrics)")

        st.markdown("""
        Le systÃ¨me est optimisÃ© pour la **recommandation Top-10** (ranking) et non la prÃ©diction exacte dâ€™une note.
        Les mÃ©triques Ã©valuent la qualitÃ© du classement des films pertinents.
        """)

        col1, col2 = st.columns(2)

        with col1:
            st.info("""
            ### ğŸ”¹ Precision@10
            Proportion de recommandations pertinentes dans le Top-10.

            ğŸ‘‰ Indique la â€œpuretÃ©â€ du Top-10 (qualitÃ© immÃ©diate).
            """)
            st.latex(r"""
            Precision@10 =
            \frac{|\{pertinents\} \cap \{Top10\}|}{10}
            """)

        with col2:
            st.info("""
            ### ğŸ”¹ Recall@10
            Proportion des films pertinents retrouvÃ©s dans le Top-10.

            ğŸ‘‰ Indique la couverture des prÃ©fÃ©rences utilisateur.
            """)
            st.latex(r"""
            Recall@10 =
            \frac{|\{pertinents\} \cap \{Top10\}|}{|\{pertinents\}|}
            """)

        st.markdown("---")

        st.subheader("NDCG@10")

        col1, col2 = st.columns(2)

        with col1:
            st.info("""
            NDCG@10 valorise :
            - la pertinence
            - la position dans le ranking

            ğŸ‘‰ Un film pertinent en rank 1 â€œvautâ€ plus quâ€™en rank 10.
            """)

        with col2:
            st.markdown("""
                **DCG@10** : somme des films pertinents pondÃ©rÃ©e par leur position dans le classement.

                ğŸ‘‰ Plus un film pertinent apparaÃ®t haut dans le Top-10, plus sa contribution est importante.
                """)

            st.markdown("""
                **NDCG@10** : version normalisÃ©e du DCG.

                ğŸ‘‰ Permet de comparer les modÃ¨les entre eux sur une Ã©chelle comprise entre 0 et 1.
                1 = classement parfait.
                """)

        st.markdown("---")

        key_takeaways("Pourquoi ces mÃ©triques ?", [
            "Le produit est un moteur de ranking (Top-10), pas une rÃ©gression sur la note",
            "NDCG@10 = mÃ©trique qui permer de tenir compte de lâ€™ordre des recommandations",
            "Precision@10 et Recall@10 complÃ¨tent lâ€™Ã©valuation (qualitÃ© / couverture)",
        ])

    elif section == "Suivi des ExpÃ©riences via MLflow":
        slide_header(
            "ğŸ“Š Suivi des ExpÃ©riences via MLflow",
            "TraÃ§abilitÃ©, reproductibilitÃ©, gouvernance modÃ¨le (Registry + alias production)"
        )

        col_logo, col_txt = st.columns([1, 3])
        with col_logo:
            show_png_if_exists("MLflow-logo", png_map, caption=None)
        with col_txt:
            st.markdown("""
            MLflow est utilisÃ© comme **systÃ¨me central de tracking & registry** :
            - suivi des runs (params, mÃ©triques, artefacts)
            - comparaison dâ€™expÃ©riences
            - gouvernance modÃ¨le via **Model Registry**
            - promotion contrÃ´lÃ©e en production via **alias `@production`**
            """)

        st.markdown("---")

        st.subheader("ğŸ¯ Objectifs MLOps couverts")

        col1, col2 = st.columns(2)
        with col1:
            st.info("""
            âœ”ï¸ Tracer chaque entraÃ®nement (runs)  
            âœ”ï¸ Logger hyperparamÃ¨tres (ex: k_neighbors)  
            âœ”ï¸ Logger mÃ©triques **Top-10** : ndcg_10, recall_10, precision_10  
            âœ”ï¸ Sauvegarder le modÃ¨le (PyFunc) comme artefact  
            âœ”ï¸ ReproductibilitÃ© / auditabilitÃ©  
            """)
        with col2:
            st.info("""
            âœ”ï¸ Versioning du modÃ¨le dans le Registry  
            âœ”ï¸ Gouvernance : alias `production`  
            âœ”ï¸ Promotion automatique basÃ©e sur mÃ©triques  
            âœ”ï¸ Historique complet des versions  
            âœ”ï¸ Tag git_commit pour relier code â†” run  
            """)

        st.markdown("---")

        st.subheader("ğŸ§ª Tracking des runs (params + mÃ©triques + artefacts)")
        displayed = show_png_if_exists(
            "mlflow_runs_metriques",
            png_map,
            caption="Liste des runs : comparaison des mÃ©triques et hyperparamÃ¨tres (k_neighbors)."
        )
        if not displayed:
            st.warning("Image 'mlflow_runs_metriques.png' introuvable (place-la dans Reports/figures/).")

        st.markdown("---")

        st.subheader("ğŸ“ˆ Comparaison dâ€™expÃ©riences (visualisations MLflow)")
        displayed = show_png_if_exists(
            "mlflow_run_comparaison",
            png_map,
            caption="Comparaison multi-runs : impact de k_neighbors sur recall_10 / ndcg_10 / precision_10."
        )
        if not displayed:
            st.warning("Image 'mlflow_run_comparaison.png' introuvable (place-la dans Reports/figures/).")

        st.markdown("---")

        st.subheader("ğŸ” DÃ©tail dâ€™un run : mÃ©triques, paramÃ¨tres, tags")
        displayed = show_png_if_exists(
            "mlflow_run_k10v8",
            png_map,
            caption="DÃ©tail dâ€™un run : mÃ©triques + paramÃ¨tres + tag git_commit + modÃ¨le enregistrÃ©."
        )
        if not displayed:
            st.warning("Image 'mlflow_run_k10v8.png' introuvable (place-la dans Reports/figures/).")

        st.markdown("""
        **Points clÃ©s :**
        - mÃ©triques Top-10 disponibles (ndcg_10, recall_10, precision_10)
        - paramÃ¨tres explicites (k_neighbors, min_ratings)
        - tag **git_commit** : traÃ§abilitÃ© code â†’ run
        """)

        st.markdown("---")

        st.subheader("ğŸ·ï¸ Model Registry & Alias `@production` (contrat de dÃ©ploiement)")
        col1, col2 = st.columns(2)
        with col1:
            st.success("""
            Le service de prÃ©diction charge toujours :

            **models:/reco-films-itemcf-v2@production**

            ğŸ‘‰ aucune rÃ©fÃ©rence directe Ã  une version dans le code.
            """)
        with col2:
            st.success("""
            La promotion en production met Ã  jour **uniquement lâ€™alias** :
            - rollback simple
            - gouvernance centralisÃ©e
            - dÃ©couplage code / modÃ¨le
            """)

        displayed = show_png_if_exists(
            "mlflow_registry_alias",
            png_map,
            caption="Model Registry : versions + alias @production sur la version active."
        )
        if not displayed:
            st.warning("Image 'mlflow_registry_alias.png' introuvable (place-la dans Reports/figures/).")

        st.markdown("---")

        st.subheader("ğŸš€ Promotion automatique : score pondÃ©rÃ© (gouvernance modÃ¨le)")

        st.markdown("""
        La promotion nâ€™est plus basÃ©e uniquement sur NDCG.
        Nous utilisons une rÃ¨gle simple, explicable et stable :

        """)
        st.latex(r"""
        Score = 0.6 \cdot NDCG@10 + 0.3 \cdot Precision@10 + 0.1 \cdot Recall@10
        """)

        st.info("""
        **Pourquoi ce choix ?**
        - NDCG@10 prioritaire : qualitÃ© du ranking (position)
        - Precision@10 : qualitÃ© brute du Top-10
        - Recall@10 : couverture des prÃ©fÃ©rences utilisateur
        """)

        st.markdown("---")

        key_takeaways("Valeur ajoutÃ©e MLflow dans ce projet :", [
            "TraÃ§abilitÃ© complÃ¨te des expÃ©rimentations (params, mÃ©triques, artefacts)",
            "ReproductibilitÃ© + auditabilitÃ© (tag git_commit)",
            "Gouvernance modÃ¨le via Registry + alias @production",
            "Promotion contrÃ´lÃ©e et rÃ©versible (rollback simple)",
        ])
        
    elif section == "Monitoring & maintenance":

            ML_cycle_IMG = ROOT / "src" / "streamlit" / "ML_cycle.png"
            grafana_icon_IMG = ROOT / "src" / "streamlit" / "grafana_icon.png"
            grafana_dashboards_IMG = ROOT / "src" / "streamlit" / "grafana_dashboards.png"
            grafana_pipelineHealth_IMG = ROOT / "src" / "streamlit" / "grafana_pipelineHealth.png"
            grafana_KPIannuels_IMG = ROOT / "src" / "streamlit" / "grafana_KPIannuels.png"
            grafana_KPImensuels_IMG = ROOT / "src" / "streamlit" / "grafana_KPImensuels.png"
            grafana_monitoringQuo_IMG = ROOT / "src" / "streamlit" / "grafana_MonitoringQuo.png"
            grafana_dataDrift_IMG = ROOT / "src" / "streamlit" / "grafana_dataDrift.png"
            grafana_dataQuality_IMG = ROOT / "src" / "streamlit" / "grafana_dataQuality.png"

            slide_header("ğŸ“ˆ Monitoring & Maintenance")

            col1, col2 = st.columns([1.2, 1])
            with col1:
                st.info("""
                ## ğŸ¯ Principe
                ### Le monitoring est **transversal** au cycle de vie du modÃ¨le.  
                Il intervient Ã  chaque Ã©tape :  
                            - ingestion des nouvelles donnÃ©es,  
                            - data processig (surveillance data drift),  
                            - training du modÃ¨le,   
                            - performance et utilisation du produit,
                
                Il se place aussi au niveau des **infrastructures** et du suivi du **dÃ©veloppement mÃ©tier** (outil d'aide Ã  la dÃ©cision)
                """)

            with col2:
                if ML_cycle_IMG.exists():
                    st.image(str(ML_cycle_IMG), width=600)
                else:
                    st.error("âŒ Image cycle ML introuvable")

            st.divider()

            st.markdown("""
                ## ğŸ” Surveillance continue""")

            col1, col2 = st.columns([1.2, 1])
            with col1:
                st.markdown("""   
                ### 1ï¸âƒ£ DonnÃ©es
                - Process d'ingestion (durÃ©e, statut, volumÃ©trie)
                -  QualitÃ© des donnÃ©es
                -  Data drift (notes, genres, PSI, nouvautÃ©s)
                -  KPI mÃ©tiers

                ### 2ï¸âƒ£ ModÃ¨le
                -  DurÃ©e d'entraÃ®nement
                -  mÃ©triques de performance
                -  gestion du cold-start
                -  back-testing aprÃ¨s dÃ©ploiement
                """)

            with col2:
                st.markdown("""
                ### 3ï¸âƒ£ Produit (API)
                - Performances techniques
                - Utilisation
                - Cold-start & performance prÃ©dictions online

                ### 4ï¸âƒ£ Infrastructure
                - CPU / MÃ©moire
                - Stockage
                - DisponibilitÃ©
                """)

            st.divider()

            st.markdown("## ğŸ“Š DÃ©ploiement du monitoring")
            col1, col2 = st.columns(2)

            with col1:
                st.success("""
                ### âœ”ï¸ Monitoring Data
                - Ingestion des donnÃ©es
                - KPI croissance & nouveautÃ©
                - Data drift (PSI)
                """)

            with col2:
                st.success("""
                ### âœ”ï¸ Monitoring ModÃ¨le
                - Training logs
                - recall@K / ndcg@K
                - Promotion automatique
                """)

            st.markdown("## ğŸ–¥ Dashboards Grafana")

            col1, col2 = st.columns(2)
            with col1:
                if grafana_icon_IMG.exists():
                    st.image(str(grafana_icon_IMG), width=200)
                else:
                    st.error("âŒ Image grafana_icon introuvable")

            with col2:
                if grafana_dashboards_IMG.exists():
                    st.image(str(grafana_dashboards_IMG), caption="Dashboards Ingestion, training et Data Grafana", width=900)
                else:
                    st.error("âŒ Image grafana_dashboardsicon introuvable")

            col1, col2 = st.columns(2)
            with col1:
                if grafana_pipelineHealth_IMG.exists():
                    st.image(str(grafana_pipelineHealth_IMG), caption="Dashboard Grafana Pipeline Health - Vision sur l'ensemble des runs", width=600)
                else:
                    st.error("âŒ Image grafana_pipelineHealth introuvable")

            with col2:
                if grafana_dataQuality_IMG.exists():
                    st.image(str(grafana_dataQuality_IMG), caption="Dashboard Grafana data Quality - Focus sur un run", width=600)
                else:
                    st.error("âŒ Image grafana_dataQuality introuvable")

            col1, col2 = st.columns(2)
            with col1:
                if grafana_dataDrift_IMG.exists():
                    st.image(str(grafana_dataDrift_IMG), caption="Dashboard Grafana Drift - PSI notes et genres - Note moyenne", width=600)
                else:
                    st.error("âŒ Image grafana_dataDrift introuvable")

            with col2:
                if grafana_KPIannuels_IMG.exists():
                    st.image(str(grafana_KPIannuels_IMG), caption="Dashboard Grafana KPIs annuels - Notes, new users & movies, note moyenne, PSI genre, %rRomance", width=600)
                else:
                    st.error("âŒ Image grafana_KPIannuels introuvable")

            col1, col2 = st.columns(2)
            with col1:
                if grafana_KPImensuels_IMG.exists():
                    st.image(str(grafana_KPImensuels_IMG), caption="Dashboard Grafana KPIs mensuels - Nb notes, note moyenne - (new) users, movies", width=600)
                else:
                    st.error("âŒ Image grafana_KPImensuels introuvable")

            with col2:
                if grafana_monitoringQuo_IMG.exists():
                    st.image(str(grafana_monitoringQuo_IMG), caption="Dashboard Grafana Monitoring quotidien - Notes, (new) users, new movies", width=600)
                else:
                    st.error("âŒ Image grafana_monitoringQuo introuvable")

            st.divider()

            st.markdown("## ğŸš§ Monitoring Produit & Infrastructure â€” Ã€ mettre en place")

            col1, col2 = st.columns(2)

            with col1:
                st.info("""
                ### ğŸ¬ Monitoring Produit (API de reco)

                ğŸ”¹ Nombre de requÃªtes, taux d'erreur  
                ğŸ”¹ Latence moyenne & p95  
                ğŸ”¹ Nombre d'utilisateurs, taux de rebond, temps d'utilisation  
                ğŸ”¹ Cold-start (nouveaux utilisateurs / nouveaux films)  
                ğŸ”¹ Taux d'adoption / satisfaction des recommandations  

                ğŸ‘‰ Objectif : mesurer l'usage rÃ©el et la performance en ligne
                """)

            with col2:
                st.info("""
                ### ğŸ–¥ Monitoring Infrastructure

                ğŸ”¹ Charge CPU des containers  
                ğŸ”¹ Utilisation mÃ©moire  
                ğŸ”¹ Espace disque (base PostgreSQL + artifacts MLflow)  
                ğŸ”¹ DisponibilitÃ© des services  
                ğŸ”¹ Temps de rÃ©ponse base de donnÃ©es  

                ğŸ‘‰ Objectif : garantir stabilitÃ© et scalabilitÃ©
                """)

            st.warning("""
            ğŸ’¡ Ã‰volution prÃ©vue :
            - IntÃ©gration Prometheus + Grafana pour mÃ©triques techniques  
            - Mise en place d'alertes automatiques (latence, erreurs, drift critique, baisse de pertinence des prÃ©dictions)  
            - Dashboard unifiÃ© : Data + ModÃ¨le + Produit + Infra  
            """)

            st.divider()

            st.markdown("""
            ## ğŸ”§ StratÃ©gie de maintenance â€” Prochaines Ã©tapes

            Le pipeline est aujourd'hui monitorÃ© (ingestion, drift, training, promotion automatique).  
            **La prochaine Ã©tape consiste Ã  renforcer sa robustesse via la formulation de rÃ¨gles de gestion et de l'automatisation :**  

            - ğŸ”„ RÃ©-entraÃ®nement conditionnel en cas de drift ou baisse de performance
            - ğŸš¦ Validation automatique des mÃ©triques avant promotion modÃ¨le  
            - ğŸ” StratÃ©gie formalisÃ©e de rollback via l'alias MLflow `production`  
            - ğŸ§ª Tests automatisÃ©s ingestion â†’ snapshot â†’ training (CI)  
            - ğŸš€ DÃ©ploiement API Docker automatisÃ© (CD)
            """)

            st.warning("Objectif : passer d'un pipeline fonctionnel en phase test Ã  un systÃ¨me MLOps sÃ©curisÃ© et industrialisable.")

            st.divider()

            st.markdown("""
                ### ğŸ— Industrialisation â€” CI/CD 
                **Objectif : sÃ©curiser le pipeline d'ingestion, le modÃ¨le ML et le dÃ©ploiement API pour garantir un systÃ¨me fiable et industrialisable**  
                (empÃªcher qu'un code, des donnÃ©es ou un modÃ¨le dÃ©gradÃ© atteigne la production).  
                ğŸ‘‰ Passer d'un pipeline monitorÃ© en phase de test  Ã  un systÃ¨me sÃ©curisÃ© et automatisÃ© en production.
                """)

            col1, col2 = st.columns(2)

            with col1:
                st.success("""
                ## âœ”ï¸ INITIÃ‰ (Phase test)

                ğŸ”¹ Pipeline d'ingestion monitorÃ© (durÃ©e, statut, volumÃ©trie)  
                ğŸ”¹ Monitoring data drift & KPI mÃ©tiers  
                ğŸ”¹ Training monitorÃ© (logs SQL + MLflow)  
                ğŸ”¹ Promotion automatique du meilleur modÃ¨le  
                ğŸ”¹ Containers Docker existants  
                ğŸ”¹ Orchestration batch quotidienne  

                ğŸ‘‰ Pipeline fonctionnel et monitorÃ©
                """)

            with col2:
                st.info("""
                ## ğŸš§ Ã€ METTRE EN PLACE

                ### ğŸ”„ CI (Avant merge)
                - Lint automatique (qualitÃ© code)
                - Tests unitaires ingestion / snapshot / training / prÃ©diction
                - Seuil de validation du modÃ¨le
                - Blocage automatique si rÃ©gression

                ### ğŸš€ CD (AprÃ¨s merge)
                - Build Docker automatisÃ© via GitHub Actions
                - DÃ©ploiement automatique API
                - Promotion modÃ¨le conditionnelle
                - Rollback version prÃ©cÃ©dente si dÃ©gradation

                ğŸ‘‰ Passage Ã  un systÃ¨me industrialisable
                """)

            st.divider()

            st.warning("""
            ğŸ”’ Prochaine Ã©tape clÃ© :
            Coupler monitoring + CI/CD pour empÃªcher toute rÃ©gression data, modÃ¨le ou API d'atteindre la production.
            """)

    elif section == "Conclusion & perspectives":
        slide_header("Conclusion & perspectives")
        st.markdown("""
          #### Ce projet a permis de concevoir un **systÃ¨me de recommandation de films**, structurÃ© autour d'une approche MLOps.
                    
        ## ğŸ” Rappel des objectifs MLOps visÃ©s
        - Faciliter la prise en main et le dÃ©ploiement du produit  
        - Garantir la reproductibilitÃ© des entraÃ®nements  
        - Assurer la fiabilitÃ© et la stabilitÃ© Ã  long terme  

        ---

        ## âœ”ï¸ Ce qui a Ã©tÃ© accompli

        - Mise en place d'un pipeline batch automatisÃ© : ingestion â†’ snapshot â†’ training â†’ promotion â†’ dÃ©ploiement  
        - Architecture append-only avec vues "current" garantissant traÃ§abilitÃ© et historisation  
        - Monitoring transverse des process et des donnÃ©es via Grafana (qualitÃ©, KPI, drift)  
        - Suivi des performances modÃ¨le (recall@K, ndcg@K) via MLflow  
        - Promotion automatique du meilleur modÃ¨le  
        - Versioning des donnÃ©es (DVC), du code (Git), des modÃ¨les (MLflow)
        - Conteneurisation Docker de tous les services pour la reproductibilitÃ©  

        Le systÃ¨me ne repose pas sur une classification ou une rÃ©gression classique,
        mais sur un **algorithme de recommandation collaborative**,  
        oÃ¹ la dÃ©rive vient principalement des **Ã©volutions de comportements utilisateurs** (notations)
        et des problÃ©matiques de **cold-start**.

        ---

        ## ğŸš§ Ce qui reste Ã  mettre en place

        - Validation automatique des mÃ©triques avant promotion  
        - Gestion robuste du cold-start et suivi de la couverture modÃ¨le    
        - Monitoring produit (usage API, latence, adoption des recommandations)  
        - Monitoring infrastructure (CPU, mÃ©moire, disponibilitÃ©)  
        - Formalisation d'une stratÃ©gie de maintenance (automatisation de la gÃ©nÃ©ration et de la gestion des alertes, notamment retraining conditionnel )  
        - Industrialisation complÃ¨te via CI/CD     
        """)

        st.warning("ğŸš€ Le projet passe ainsi d'un pipeline fonctionnel en phase de test Ã  une base solide pour un systÃ¨me de recommandation industrialisable.")

def show_demo_mode():
    st.markdown("## ğŸ¿ DÃ©monstration Live")
    
    api_is_alive = check_api_health()
    if api_is_alive:
        st.sidebar.success(f"ğŸŸ¢ API ConnectÃ©e")
    else:
        st.sidebar.error(f"ğŸ”´ API DÃ©connectÃ©e")
        st.error(f"Impossible de contacter l'API sur : {API_URL}")
        return

    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ‘¤ Recommandation Utilisateur", 
        "ğŸ”¥ Films Populaires", 
        "ğŸ§  MÃ©tadonnÃ©es ModÃ¨le",
        "ğŸ–¥ï¸ Statut SystÃ¨me"
    ])

    with tab1:
        st.subheader("Simuler un utilisateur")
        
        col_input, col_action = st.columns([1, 2])
        with col_input:
            user_id = st.number_input("User ID", min_value=1, value=1, step=1)
            top_n = st.slider("Nombre de films", min_value=1, max_value=10, value=5)
            
        btn_reco = st.button("âœ¨ GÃ©nÃ©rer les recommandations", type="primary")

        if btn_reco:
            with st.spinner(f"Calcul des recommandations pour User {user_id}..."):
                try:
                    response = requests.get(f"{API_URL}/recommend", params={"user_id": user_id, "top_n": top_n})
                    
                    if response.status_code == 200:
                        data = response.json()
                        recos = data.get("recommendations", [])
                        
                        if not recos:
                            st.warning("Aucune recommandation trouvÃ©e.")
                        else:
                            st.success(f"Top {len(recos)} pour l'utilisateur {user_id}")
                            df_reco = pd.DataFrame(recos)
                            calc_height = (35 * len(recos) + 38)
                            
                            st.dataframe(
                                df_reco,
                                column_config={
                                    "movie_id": st.column_config.NumberColumn("ID Film", format="%d"),
                                    "title": st.column_config.TextColumn("Titre du film"),
                                    "score": st.column_config.ProgressColumn(
                                        "Score de Pertinence",
                                        format="%.3f",
                                        min_value=0,
                                        max_value=df_reco["score"].max() + 0.5,
                                    ),
                                },
                                hide_index=True,
                                use_container_width=True,
                                height=calc_height
                            )
                            with st.expander("Voir la rÃ©ponse JSON brute"):
                                st.json(data)
                    else:
                        st.error(f"Erreur API : {response.status_code} - {response.text}")
                except Exception as e:
                    st.error(f"Erreur de connexion : {str(e)}")

    with tab2:
        st.subheader("ScÃ©nario Cold Start")
        if st.button("Charger les populaires"):
            try:
                res = requests.get(f"{API_URL}/movies/popular", params={"limit": 20})
                if res.status_code == 200:
                    pop_movies = res.json()
                    flat_data = []
                    for m in pop_movies:
                        flat_data.append({
                            "Titre": m["title"],
                            "Score BayÃ©sien": m["stats"]["score"],
                            "Note Moyenne": m["stats"]["mean_rating"],
                            "Nb Votes": m["stats"]["count"]
                        })
                    st.dataframe(pd.DataFrame(flat_data), use_container_width=True)
            except Exception as e:
                st.error(e)

    with tab3:
        st.subheader("ğŸ“¦ ObservabilitÃ© du ModÃ¨le")
        c_refresh, c_link = st.columns([1, 4])
        with c_refresh:
            btn_refresh = st.button("ğŸ”„ RafraÃ®chir MÃ©tadonnÃ©es")
        with c_link:
             st.link_button("ğŸš€ Ouvrir MLFlow UI", MLFLOW_EXTERNAL_URL)

        if btn_refresh:
            try:
                res_config = requests.get(f"{API_URL}/model/config")
                res_meta = requests.get(f"{API_URL}/model/metadata")
                
                config_data = res_config.json()
                meta_data = res_meta.json()

                st.markdown("#### ğŸ†” IdentitÃ© du Run MLflow")
                col1, col2, col3 = st.columns(3)
                run_id = meta_data.get("run_id", "N/A")
                col1.metric("Run ID", run_id)
                col2.metric("Version ModÃ¨le", meta_data.get("model_version", "Latest"))
                col3.metric("Status", "Production", delta="Active")
                
                st.divider()
                st.markdown("#### âš™ï¸ HyperparamÃ¨tres")
                if config_data and "detail" not in config_data:
                    st.table(pd.DataFrame(list(config_data.items()), columns=["ParamÃ¨tre", "Valeur"]))
                else:
                    st.warning("Configuration non disponible.")

                st.divider()
                st.markdown("#### ğŸ“Š MÃ©triques du ModÃ¨le")
                metrics = meta_data.get("metrics", {})
                if metrics:
                    cols = st.columns(len(metrics))
                    for col, (k, v) in zip(cols, metrics.items()):
                        col.metric(k, f"{v:.4f}" if isinstance(v, float) else v)
                else:
                    st.info("Aucune mÃ©trique enregistrÃ©e pour ce run.")

                st.divider()
                st.markdown("#### ğŸ·ï¸ Tags & TraÃ§abilitÃ© Dataset")
                tags = meta_data.get("tags", {})
                dvc_hash = tags.get("dvc_dataset_hash", "N/A")
                git_commit = tags.get("git_commit", "N/A")

                col1, col2 = st.columns(2)
                col1.code(f"DVC Hash : {dvc_hash}", language="text")
                col2.code(f"Git Commit : {git_commit}", language="text")

                if tags:
                    with st.expander("Voir tous les tags"):
                        st.table(pd.DataFrame(list(tags.items()), columns=["Tag", "Valeur"]))

            except Exception as e:
                st.error(f"Impossible de rÃ©cupÃ©rer les mÃ©tadonnÃ©es : {e}")
        
        st.markdown("---")
        st.subheader("ğŸ› ï¸ Actions Rapide")
        if st.button("RÃ©-entraÃ®ner le modÃ¨le", type="secondary"):
            status_train = st.status("DÃ©marrage du pipeline d'entraÃ®nement...", expanded=True)
            try:
                res_train = requests.post(f"{API_URL}/training", timeout=600)
                if res_train.status_code == 200:
                    status_train.update(label="EntraÃ®nement terminÃ© !", state="complete", expanded=False)
                    st.success("Nouveau modÃ¨le entraÃ®nÃ© !")
                    st.balloons()
                else:
                    status_train.update(label="Erreur", state="error")
                    st.error(res_train.text)
            except Exception as e:
                status_train.update(label="Erreur connexion", state="error")
                st.error(str(e))

    with tab4:
        st.subheader("ğŸ–¥ï¸ SantÃ© du SystÃ¨me")
        
        if st.button("Lancer les Diagnostics", type="primary"):
            status_container = st.status("Analyse des composants...", expanded=True)
            
            t0 = time.time()
            try:
                requests.get(f"{API_URL}/health", timeout=2)
                latency = (time.time() - t0) * 1000
                api_ok = True
            except:
                latency = 0
                api_ok = False
            
            try:
                mf_res = requests.get(MLFLOW_INTERNAL_URL, timeout=1)
                mlflow_ok = (mf_res.status_code == 200)
            except:
                mlflow_ok = False
            
            try:
                ready_res = requests.get(f"{API_URL}/ready", timeout=5)
                checks = ready_res.json().get("checks", {})
                db_status = checks.get("database", "error")
                model_status = checks.get("model", "error")
            except:
                db_status = "unreachable"
                model_status = "unreachable"

            status_container.update(label="TerminÃ© !", state="complete", expanded=False)

            col1, col2, col3, col4 = st.columns(4)
            col1.metric("FastAPI", "En Ligne" if api_ok else "Hors Ligne", f"{latency:.0f} ms" if api_ok else None)
            col2.metric("PostgreSQL", "ConnectÃ©" if db_status == "connected" else "Erreur")
            col3.metric("MLFlow Server", "Accessible" if mlflow_ok else "Inaccessible")
            col4.metric("ModÃ¨le IA", "ChargÃ©" if model_status == "ready" else "Erreur")
            
        st.divider()
        st.markdown("#### ğŸ› ï¸ Actions Rapides")
        
        if st.button("Relancer Ingestion DonnÃ©es"):
                try:
                    with st.spinner("Pipeline ingestion en cours..."):
                        requests.post(f"{API_URL}/data")
                        st.toast("Pipeline ingestion lancÃ© avec succÃ¨s !", icon="ğŸš€")
                        st.success("Ingestion terminÃ©e.")
                except:
                    st.error("Ã‰chec appel API")

st.title(APP_TITLE)
mode = st.sidebar.selectbox("Choisir le mode :", ["PrÃ©sentation (Slides)", "Application DÃ©mo"])
if mode == "PrÃ©sentation (Slides)":
    show_presentation_mode()
else:
    show_demo_mode()