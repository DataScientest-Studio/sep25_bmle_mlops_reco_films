# src/ingestion/ingestion_movielens.py
# ------------------------------------------------------------
# OBJECTIF
# ------------------------------------------------------------
# Ce script remplace l'ingestion SQLite (fichier .db sur disque)
# par une ingestion DIRECTE dans PostgreSQL (serveur SQL local).
#
# Pourquoi ?
# - SQLite = base "embarqu√©e" : acc√®s via un fichier local (.sqlite)
# - PostgreSQL = base "serveur" : acc√®s via localhost:5432 (port r√©seau)
#
# R√©sultat :
# - Une "vraie" base qui tourne comme un service.
# - Ton pipeline n'est plus d√©pendant d'un chemin local vers un .db.
#
# ------------------------------------------------------------
# PR√âREQUIS
# ------------------------------------------------------------
# 1) Lancer PostgreSQL en local (Docker recommand√©)
#    docker compose up -d
#
# 2) Installer d√©pendances Python
#    pip install pandas sqlalchemy psycopg2-binary
#
# 3) Avoir les CSV dans data/raw/
#    movies.csv, ratings.csv, tags.csv, links.csv, genome-scores.csv, genome-tags.csv
#
# 4) Variable d'environnement possible (optionnel)
#    PG_URL=postgresql+psycopg2://movie:movie@localhost:5432/movie_reco
#    PG_SCHEMA=raw
#
# ------------------------------------------------------------
# TABLES CR√â√âES DANS POSTGRES
# ------------------------------------------------------------
# Sch√©ma (namespace) : raw (par d√©faut)
#
# - raw.raw_movies
# - raw.raw_ratings
# - raw.raw_tags
# - raw.raw_links
# - raw.raw_genome_scores
# - raw.raw_genome_tags
#
# + table de suivi :
# - raw.ingestion_metadata
#
# ingestion_metadata contient :
# - table_name : nom logique (movies, ratings, ...)
# - row_count : nombre de lignes ing√©r√©es
# - column_count : nombre de colonnes ing√©r√©es
# - ingestion_date : date/heure de la derni√®re ingestion
# ------------------------------------------------------------

from __future__ import annotations

import os
from pathlib import Path

import pandas as pd
from sqlalchemy import create_engine, text


# Mapping "nom logique" -> "nom de fichier"
# Le nom logique sert √† construire le nom de table raw_<name>.
CSV_FILES = {
    "movies": "movies.csv",
    "ratings": "ratings.csv",
    "tags": "tags.csv",
    "links": "links.csv",
    "genome_scores": "genome-scores.csv",
    "genome_tags": "genome-tags.csv",
}


def _get_postgres_engine(pg_url: str):
    """
    Cr√©e un 'engine' SQLAlchemy.

    Un engine est un objet qui sait :
    - ouvrir des connexions √† la base (pool de connexions)
    - ex√©cuter des requ√™tes SQL
    - √™tre utilis√© par pandas.to_sql()

    Ici on utilise PostgreSQL via psycopg2.
    """
    return create_engine(pg_url)


def _ensure_schema_and_metadata_table(engine, schema: str) -> None:
    """
    - Cr√©e le sch√©ma si n√©cessaire (√©quivalent d'un dossier/namespace SQL)
    - Cr√©e la table ingestion_metadata si elle n'existe pas

    Note :
    - Dans PostgreSQL, un "schema" (ex: raw) organise les tables.
      √áa √©vite de polluer 'public' et c'est plus propre en projet.
    """
    with engine.begin() as conn:
        # CREATE SCHEMA IF NOT EXISTS raw;
        conn.execute(text(f"CREATE SCHEMA IF NOT EXISTS {schema};"))

        # Cr√©e la table de m√©tadonn√©es si n√©cessaire.
        # BIGINT pour row_count : √ßa √©vite les soucis si la table grossit.
        conn.execute(
            text(
                f"""
                CREATE TABLE IF NOT EXISTS {schema}.ingestion_metadata (
                    table_name TEXT PRIMARY KEY,
                    row_count  BIGINT,
                    column_count INTEGER,
                    ingestion_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
                """
            )
        )


def _upsert_metadata(engine, schema: str, table_name_logic: str, row_count: int, column_count: int) -> None:
    """
    Met √† jour ou ins√®re une ligne dans ingestion_metadata.

    - SQLite utilisait : INSERT OR REPLACE
    - PostgreSQL utilise : INSERT ... ON CONFLICT ... DO UPDATE

    Ici, "table_name_logic" correspond √† tes cl√©s :
    movies / ratings / tags / etc.
    """
    with engine.begin() as conn:
        conn.execute(
            text(
                f"""
                INSERT INTO {schema}.ingestion_metadata(table_name, row_count, column_count, ingestion_date)
                VALUES (:table_name, :row_count, :column_count, CURRENT_TIMESTAMP)
                ON CONFLICT (table_name)
                DO UPDATE SET
                    row_count = EXCLUDED.row_count,
                    column_count = EXCLUDED.column_count,
                    ingestion_date = EXCLUDED.ingestion_date;
                """
            ),
            {
                "table_name": table_name_logic,
                "row_count": int(row_count),
                "column_count": int(column_count),
            },
        )


def _print_metadata(engine, schema: str) -> None:
    """
    Affiche un tableau de suivi ingestion_metadata.

    C'est l'√©quivalent de ton:
    meta = pd.read_sql("SELECT * FROM ingestion_metadata ...", conn)
    print(meta.to_string(...))
    """
    meta = pd.read_sql(
        f"SELECT * FROM {schema}.ingestion_metadata ORDER BY table_name;",
        con=engine,
    )
    print("\n[METADATA] ingestion_metadata")
    print(meta.to_string(index=False))


def ingest_movielens(
    raw_dir: str = "data/raw",
    pg_url: str | None = None,
    schema: str | None = None,
    if_exists: str = "replace",
) -> None:
    """
    Ingestion MovieLens -> PostgreSQL

    Param√®tres :
    - raw_dir : dossier o√π se trouvent les CSV (data/raw)
    - pg_url  : string de connexion PostgreSQL (si None, on prend env PG_URL ou valeur par d√©faut)
    - schema  : sch√©ma SQL cible (si None, on prend env PG_SCHEMA ou "raw")
    - if_exists : comportement si la table existe d√©j√† :
        - "replace" : drop & recreate (simple pour dev / re-run)
        - "append"  : ajoute des lignes (utile si ingestion incr√©mentale)
        - "fail"    : refuse si table existe
    """
    raw_dir_path = Path(raw_dir)

    # 1) V√©rifier la pr√©sence des fichiers CSV attendus
    missing = [fn for fn in CSV_FILES.values() if not (raw_dir_path / fn).exists()]
    if missing:
        raise FileNotFoundError(
            f"Fichiers manquants dans {raw_dir_path.resolve()} : {missing}\n"
            "üëâ V√©rifie que DVC a bien r√©cup√©r√© data/raw/ (dvc pull)."
        )

    # 2) Construire les param√®tres de connexion
    #    On privil√©gie les variables d'environnement si disponibles.
    if pg_url is None:
        pg_url = os.getenv(
            "PG_URL",
            "postgresql+psycopg2://movie:movie@127.0.0.1:5432/movie_reco"
        )

    if schema is None:
        schema = os.getenv("PG_SCHEMA", "raw")

    # 3) Cr√©er l'engine SQLAlchemy
    engine = _get_postgres_engine(pg_url)

    # 4) Pr√©parer l'environnement SQL (schema + metadata)
    _ensure_schema_and_metadata_table(engine, schema)

    # 5) Boucle d'ingestion : lire CSV -> √©crire table Postgres
    for logical_name, filename in CSV_FILES.items():
        csv_path = raw_dir_path / filename

        # Lecture CSV
        # low_memory=False √©vite des inf√©rences de types "bizarres" par morceaux
        df = pd.read_csv(csv_path, low_memory=False)

        # Nom de table final (comme ton SQLite): raw_<name>
        table_name = f"raw_{logical_name}"

        # √âcriture dans PostgreSQL
        #
        # df.to_sql(...) va :
        # - cr√©er la table si elle n'existe pas
        # - pousser les donn√©es en INSERT
        # - g√©rer "replace" en drop + create + insert
        #
        # method="multi" + chunksize acc√©l√®re en envoyant des INSERT group√©s.
        df.to_sql(
            name=table_name,
            con=engine,
            schema=schema,
            if_exists=if_exists,
            index=False,
            method="multi",
            chunksize=5000,
        )

        print(
            f"[INGEST] {filename} -> {schema}.{table_name} "
            f"({df.shape[0]} lignes, {df.shape[1]} colonnes)"
        )

        # 6) Mettre √† jour ingestion_metadata
        _upsert_metadata(
            engine=engine,
            schema=schema,
            table_name_logic=logical_name,
            row_count=df.shape[0],
            column_count=df.shape[1],
        )

    # 7) Afficher metadata (r√©sum√© final)
    _print_metadata(engine, schema)


if __name__ == "__main__":
    # Lancement par d√©faut (compatible avec ton usage actuel)
    ingest_movielens()
